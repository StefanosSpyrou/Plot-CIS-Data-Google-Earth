{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CIS Data to Google Earth (Real Time)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a48fe114014d2f27"
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Functionality with meters\n",
    "# TODO: Issues with no 'On' Potential \n",
    "# TODO: Rewrite log file code"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:11.380024Z",
     "start_time": "2024-04-09T16:23:11.374201Z"
    }
   },
   "id": "c75af61d5de8ba26",
   "outputs": [],
   "execution_count": 594
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Try manual compressing methods\n",
    "\n",
    "# import zipfile\n",
    "# import simplekml\n",
    "# \n",
    "# # Create a .kml file with simplekml\n",
    "# kml = simplekml.Kml()\n",
    "# kml.newpoint(name=\"Sample\", coords=[(1.0, 2.0)])  # sample point\n",
    "# kml.save(\"sample.kml\")\n",
    "# \n",
    "# # Manually compress the .kml to .kmz using a higher compression level\n",
    "# with zipfile.ZipFile('sample.kmz', 'w', compression=zipfile.ZIP_DEFLATED, compresslevel=9) as myzip:\n",
    "#     myzip.write('sample.kml')"
   ],
   "id": "d9995a191f1213ed"
  },
  {
   "cell_type": "code",
   "source": [
    "# Standard library imports for filesystem and execution time\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Standard library import for networking\n",
    "import socket\n",
    "\n",
    "# Standard library imports for mathematical functions\n",
    "import math\n",
    "from math import atan, atan2, cos, radians, sin, sqrt, tan\n",
    "\n",
    "# Third-party imports for data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Third-party imports for KML (Keyhole Markup Language) and Excel (`xlsx`) files handling\n",
    "import simplekml\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, Alignment, Border, Side\n",
    "\n",
    "# Third-party import for filesystem path names pattern matching\n",
    "import glob\n",
    "\n",
    "# Settings for pandas\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Measuring execution time\n",
    "start_time = time.time()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:11.812311Z",
     "start_time": "2024-04-09T16:23:11.807412Z"
    }
   },
   "id": "97c56b5084f08151",
   "outputs": [],
   "execution_count": 595
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paths"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df94ac81231e9fbc"
  },
  {
   "cell_type": "code",
   "source": [
    "# Folders\n",
    "root_path = os.path.abspath('../')\n",
    "original_data_path = os.path.join(root_path, 'Original Data')\n",
    "data_path = os.path.join(root_path, 'Data')\n",
    "output_path = os.path.join(root_path, 'Output')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:11.850681Z",
     "start_time": "2024-04-09T16:23:11.847668Z"
    }
   },
   "id": "1c6a6d9c27799d6a",
   "outputs": [],
   "execution_count": 596
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:11.889978Z",
     "start_time": "2024-04-09T16:23:11.887640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Files\n",
    "log_path = os.path.join(output_path, 'Log.txt')\n",
    "duplicates_path = os.path.join(output_path, 'Duplicate GPS Pairs.csv')"
   ],
   "id": "cd83600573202df7",
   "outputs": [],
   "execution_count": 597
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5da945ccb96fe031"
  },
  {
   "cell_type": "code",
   "source": [
    "# Data Headers: 'Station, On Potential, Off Potential, Comments, Latitude, Longitude, ElevationPDOP'\n",
    "# File Name: COMPANY LINE SNXXXX TO SNXXXXX"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:11.924052Z",
     "start_time": "2024-04-09T16:23:11.922038Z"
    }
   },
   "id": "75f0e7283fe03492",
   "outputs": [],
   "execution_count": 598
  },
  {
   "cell_type": "code",
   "source": [
    "# COMPANY\n",
    "client = 'Highridge'\n",
    "\n",
    "# REVERSE DATA ROWS (True or False)\n",
    "REVERSE = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:11.988270Z",
     "start_time": "2024-04-09T16:23:11.985816Z"
    }
   },
   "id": "7c1c9a4c1290d02e",
   "outputs": [],
   "execution_count": 599
  },
  {
   "cell_type": "code",
   "source": [
    "# ICONS (On: FC9CFF, Native: 175082)\n",
    "ICON_ON = 'https://img.icons8.com/ios-filled/50/FC9CFF/filled-circle.png'\n",
    "ICON_OFF = 'https://img.icons8.com/ios-filled/50/00FF00/filled-circle.png'\n",
    "ICON_NATIVE = 'https://img.icons8.com/ios-filled/50/00FF00/filled-circle.png'  #FIX COLOR\n",
    "ICON_1200 = 'https://img.icons8.com/ios-filled/50/7950F2/filled-circle.png'\n",
    "ICON_850 = 'https://img.icons8.com/ios-filled/50/F25081/filled-circle.png'\n",
    "ICON_COMMENTS = 'https://img.icons8.com/ultraviolet/80/000000/comments.png'\n",
    "\n",
    "# SCALE FACTOR (Elevation of points, Default = 100)\n",
    "SCALE_FACTOR = 100\n",
    "\n",
    "# ICON SCALE (Default = 0.3)\n",
    "ICON_SCALE = 0.3\n",
    "\n",
    "# DATA VISIBILITY WHEN OPENING KMZ FILE (True or False)\n",
    "DATA_VISIBILITY = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:12.023400Z",
     "start_time": "2024-04-09T16:23:12.020528Z"
    }
   },
   "id": "c609f9b57d7ab2c4",
   "outputs": [],
   "execution_count": 600
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vincenty's Formula"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6087cd51a3c2120c"
  },
  {
   "cell_type": "code",
   "source": [
    "class VincentyInverse:\n",
    "    def __init__(self, coord1, coord2, maxiter=200, tol=10 ** -12):\n",
    "        # CONSTANTS\n",
    "        a = 6378137.0  # radius at equator in meters (WGS-84)\n",
    "        f = 1 / 298.257223563  # flattening of the ellipsoid (WGS-84)\n",
    "        b = (1 - f) * a\n",
    "        phi_1, lon_1, = coord1  # (lat=L_?,lon=phi_?)\n",
    "        phi_2, lon_2, = coord2\n",
    "        u_1 = atan((1 - f) * tan(radians(phi_1)))\n",
    "        u_2 = atan((1 - f) * tan(radians(phi_2)))\n",
    "        L = radians(lon_2 - lon_1)\n",
    "        lamda = L  # set initial value of lambda to L\n",
    "        sin_u1 = sin(u_1)\n",
    "        cos_u1 = cos(u_1)\n",
    "        sin_u2 = sin(u_2)\n",
    "        cos_u2 = cos(u_2)\n",
    "\n",
    "        # ITERATIONS\n",
    "        self.iters = 0\n",
    "        for i in range(0, maxiter):\n",
    "            self.iters += 1\n",
    "            cos_lambda = cos(lamda)\n",
    "            sin_lambda = sin(lamda)\n",
    "            sin_sigma = sqrt((cos_u2 * sin(lamda)) ** 2 +\n",
    "                             (cos_u1 * sin_u2 - sin_u1 * cos_u2 * cos_lambda) ** 2)\n",
    "            cos_sigma = sin_u1 * sin_u2 + cos_u1 * cos_u2 * cos_lambda\n",
    "            sigma = atan2(sin_sigma, cos_sigma)\n",
    "            sin_alpha = (cos_u1 * cos_u2 * sin_lambda) / sin_sigma\n",
    "            cos_sq_alpha = 1 - sin_alpha ** 2\n",
    "            cos2_sigma_m = cos_sigma - ((2 * sin_u1 * sin_u2) / cos_sq_alpha)\n",
    "            C = (f / 16) * cos_sq_alpha * (4 + f * (4 - 3 * cos_sq_alpha))\n",
    "            Lambda_prev = lamda\n",
    "            lamda = L + (1 - C) * f * sin_alpha * (sigma + C * sin_sigma *\n",
    "                                                   (cos2_sigma_m + C * cos_sigma *\n",
    "                                                    (-1 + 2 * cos2_sigma_m ** 2)))\n",
    "\n",
    "            # Successful convergence\n",
    "            diff = abs(Lambda_prev - lamda)\n",
    "            if diff <= tol:\n",
    "                break\n",
    "\n",
    "        u_sq = cos_sq_alpha * ((a ** 2 - b ** 2) / b ** 2)\n",
    "        A = 1 + (u_sq / 16384) * (4096 + u_sq * (-768 + u_sq * (320 - 175 * u_sq)))\n",
    "        B = (u_sq / 1024) * (256 + u_sq * (-128 + u_sq * (74 - 47 * u_sq)))\n",
    "        delta_sig = B * sin_sigma * (cos2_sigma_m + 0.25 * B *\n",
    "                                     (cos_sigma * (-1 + 2 * cos2_sigma_m ** 2) -\n",
    "                                      (1 / 6) * B * cos2_sigma_m * (-3 + 4 * sin_sigma ** 2) *\n",
    "                                      (-3 + 4 * cos2_sigma_m ** 2)))\n",
    "\n",
    "        self.m = b * A * (sigma - delta_sig)  # Meters\n",
    "        self.miles = self.m * 0.000621371  # Miles\n",
    "        self.ft = self.miles * 5280  # Feet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:12.082018Z",
     "start_time": "2024-04-09T16:23:12.073442Z"
    }
   },
   "id": "ede29dcf57a782d6",
   "outputs": [],
   "execution_count": 601
  },
  {
   "cell_type": "markdown",
   "source": "# Data Cleaning",
   "metadata": {
    "collapsed": false
   },
   "id": "2d50de70870fd6f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Folder Management",
   "id": "d6d89a2720c333ba"
  },
  {
   "cell_type": "code",
   "source": [
    "# Replaces data folder with an empty one\n",
    "if os.path.exists(data_path):\n",
    "    shutil.rmtree(data_path)\n",
    "\n",
    "os.makedirs(data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:12.097074Z",
     "start_time": "2024-04-09T16:23:12.093287Z"
    }
   },
   "id": "1765b77ca98037cb",
   "outputs": [],
   "execution_count": 602
  },
  {
   "cell_type": "code",
   "source": [
    "# Replaces output folder with an empty one\n",
    "if os.path.exists(output_path):\n",
    "    shutil.rmtree(output_path)\n",
    "\n",
    "os.makedirs(output_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:12.141283Z",
     "start_time": "2024-04-09T16:23:12.114153Z"
    }
   },
   "id": "8b67b809883fe68a",
   "outputs": [],
   "execution_count": 603
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Log File",
   "id": "c6940757b6f2532b"
  },
  {
   "cell_type": "code",
   "source": [
    "# Removes existing log file, if it exists\n",
    "if os.path.exists(log_path):\n",
    "    os.remove(log_path)\n",
    "\n",
    "# Creates a log file to track information of interest\n",
    "with open(log_path, 'a') as f:\n",
    "    f.write('Rows dropped with missing GPS points: ')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:12.177434Z",
     "start_time": "2024-04-09T16:23:12.174579Z"
    }
   },
   "id": "e1f39b54427721c1",
   "outputs": [],
   "execution_count": 604
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clean Raw Files",
   "id": "aa0da93d53ad1eb2"
  },
  {
   "cell_type": "code",
   "source": [
    "# List of files contained in the original data folder\n",
    "raw_data_list = os.listdir(original_data_path)\n",
    "\n",
    "# List for files excluding ones starting with '.'\n",
    "filtered_data_list = [file for file in raw_data_list if not file.startswith('.')]\n",
    "\n",
    "# Removes '.DAT' string from any files that have it\n",
    "for idx, name in enumerate(filtered_data_list):\n",
    "    original_name = os.path.join(original_data_path, name)\n",
    "    new_name = os.path.join(original_data_path, name.replace('.DAT', ''))\n",
    "    os.rename(original_name, new_name)\n",
    "    filtered_data_list[idx] = name.replace('.DAT', '')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:12.226485Z",
     "start_time": "2024-04-09T16:23:12.222354Z"
    }
   },
   "id": "f14b0d756d325a17",
   "outputs": [],
   "execution_count": 605
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataframe",
   "id": "ce77610a88e5618b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO: Deal when there are missing columns",
   "id": "c0d53d0047ad1dd0"
  },
  {
   "cell_type": "code",
   "source": [
    "total_miles_list = []  # List for total miles per '.csv' file\n",
    "total_rows_dropped = []  # List for total rows dropped that don't have GPS coordinates\n",
    "i = 0  # Loop counter for calculating distance (ft)\n",
    "j = 0  # List counter for '.csv' files\n",
    "\n",
    "# Goes through all the files in the list\n",
    "while j < len(filtered_data_list):\n",
    "    # Create dataframe from a csv file\n",
    "    df_cis = pd.read_csv(os.path.join(original_data_path, filtered_data_list[j]))\n",
    "\n",
    "    # Columns\n",
    "    df_cis = df_cis[['Station', 'On Potential', 'Off Potential',\n",
    "                     'Comments', 'Latitude', 'Longitude']]\n",
    "\n",
    "    # Reversing rows for flipped SN\n",
    "    if REVERSE:\n",
    "        # Reversing rows\n",
    "        df_cis.iloc[:, :] = df_cis.iloc[:, :].values[::-1]\n",
    "\n",
    "        # Reordering\n",
    "        df_cis['Station'] = abs(max(df_cis['Station']) - df_cis['Station'])\n",
    "\n",
    "    # Delete rows that CIS was skipped and reset the index\n",
    "    df_cis = df_cis.loc[df_cis['On Potential'] != 'SKIP'].reset_index(drop=True)\n",
    "\n",
    "    # Extract starting stationing number (ft) from '.csv' title\n",
    "    starting_stationing = float(filtered_data_list[j].split('SN')[1].split()[0].replace('+', ''))\n",
    "\n",
    "    # Add 'Stationing (ft)' column to hold calculated stationing values\n",
    "    df_cis['Stationing (ft)'] = ''\n",
    "\n",
    "    # Convert object columns to numbers\n",
    "    df_cis['On Potential'] = pd.to_numeric(df_cis['On Potential'], errors='coerce')\n",
    "    df_cis['Off Potential'] = pd.to_numeric(df_cis['Off Potential'], errors='coerce')\n",
    "\n",
    "    # Replace empty values with 0\n",
    "    df_cis['On Potential'].replace(np.nan, 0, inplace=True)\n",
    "    df_cis['Off Potential'].replace(np.nan, 0, inplace=True)\n",
    "\n",
    "    # Replace exact values\n",
    "    df_cis['On Potential'].replace(-0.85, -0.850001, inplace=True)\n",
    "    df_cis['Off Potential'].replace(-0.85, -0.850001, inplace=True)\n",
    "    df_cis['Off Potential'].replace(-1.2, -1.20001, inplace=True)\n",
    "\n",
    "    # Convert positive values to negative\n",
    "    df_cis['On Potential'] = df_cis['On Potential'].abs() * (-1)\n",
    "    df_cis['Off Potential'] = df_cis['Off Potential'].abs() * (-1)\n",
    "\n",
    "    # Columns to divide by 1000 they exist\n",
    "    cols = ['On Potential', 'Off Potential', 'Native']\n",
    "    \n",
    "    for col in cols:\n",
    "        if col in df_cis.columns and abs(df_cis[col].mean()) > 100:\n",
    "            df_cis[col] /= 1000\n",
    "\n",
    "    # Trim white space from comments\n",
    "    df_cis['Comments'] = df_cis['Comments'].str.strip()\n",
    "\n",
    "    # Create 'Distance (ft)' column\n",
    "    df_cis['Distance (ft)'] = 0.00\n",
    "    last_index2 = df_cis.last_valid_index()\n",
    "\n",
    "    # Drop rows that don't have GPS coordinates\n",
    "    df_cis['Latitude'].replace('', np.nan, inplace=True)\n",
    "    df_cis.dropna(subset=['Latitude'], inplace=True)\n",
    "    df_cis.reset_index(drop=True, inplace=True)\n",
    "    last_index = df_cis.last_valid_index()\n",
    "    total_rows_dropped.append(last_index2 - last_index)\n",
    "\n",
    "    # Record number of rows dropped for each file\n",
    "    with open(log_path, 'a') as f:\n",
    "        f.write(f\"{total_rows_dropped[j]}\\n\")\n",
    "\n",
    "    # Infers actual stationing number (xxxx+xx)\n",
    "    while i <= last_index:\n",
    "        current_station = df_cis.at[i, 'Station']\n",
    "        stationing_ft = str(starting_stationing + current_station).split('.')[0]\n",
    "        string_length = len(stationing_ft)\n",
    "\n",
    "        if -100 < (starting_stationing + current_station) < 0:\n",
    "            station_value = stationing_ft.replace('-', '')\n",
    "            df_cis.at[i, 'Stationing (ft)'] = (\n",
    "                f\" -0{station_value[:string_length - 2]}+{station_value[string_length - 2:]}\"\n",
    "            )\n",
    "        elif 0 <= (starting_stationing + current_station) < 100:\n",
    "            df_cis.at[i, 'Stationing (ft)'] = (\n",
    "                f\" 0{stationing_ft[:string_length - 2]}+{stationing_ft[string_length - 2:]}\"\n",
    "            )\n",
    "        else:\n",
    "            df_cis.at[i, 'Stationing (ft)'] = (\n",
    "                f\"{stationing_ft[:string_length - 2]}+{stationing_ft[string_length - 2:]}\"\n",
    "            )\n",
    "\n",
    "        # Last row exception\n",
    "        if i != last_index:\n",
    "            # Calculates distance between GPS coordinates and stationing (ft)\n",
    "            try:\n",
    "                df_cis.at[i + 1, 'Distance (ft)'] = VincentyInverse(\n",
    "                    [df_cis.at[i, 'Latitude'], df_cis.at[i, 'Longitude']],\n",
    "                    [df_cis.at[i + 1, 'Latitude'], df_cis.at[i + 1, 'Longitude']]\n",
    "                ).ft\n",
    "\n",
    "            except ZeroDivisionError:\n",
    "                df_cis.at[i + 1, 'Distance (ft)'] = 0\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    # Calculates standard deviation between GPS coordinates\n",
    "    for i in range(1, last_index + 1):\n",
    "        df_cis.at[i, 'Error'] = (\n",
    "                df_cis.at[i, 'Distance (ft)'] - df_cis.at[i, 'Station'] +\n",
    "                df_cis.at[i - 1, 'Station']\n",
    "        )\n",
    "        std = df_cis['Error'].std()\n",
    "\n",
    "    # Drop 'Error' column\n",
    "    df_cis = df_cis.drop('Error', axis=1)\n",
    "\n",
    "    # Records total miles in a list\n",
    "    total_miles_list.append(max(df_cis['Station']) / 5280)\n",
    "\n",
    "    # Export to csv\n",
    "    df_cis.to_csv(os.path.join(data_path, filtered_data_list[j]), index=False)\n",
    "\n",
    "    # Counters\n",
    "    i = 0\n",
    "    j += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:30.141401Z",
     "start_time": "2024-04-09T16:23:12.262601Z"
    }
   },
   "id": "ca8cc75b0f341d29",
   "outputs": [],
   "execution_count": 606
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Google Earth Folders"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90d0bb4d93df8728"
  },
  {
   "cell_type": "code",
   "source": [
    "cis_kmz = []\n",
    "type_folders = []\n",
    "current_mile = 1\n",
    "k = 0  # List counter for type folders\n",
    "j = 0  # List counter for '.csv' files\n",
    "i = 0  # List counter for '.kmz' files based on miles"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:30.624572Z",
     "start_time": "2024-04-09T16:23:30.146761Z"
    }
   },
   "id": "82044ae7c448ac84",
   "outputs": [],
   "execution_count": 607
  },
  {
   "cell_type": "code",
   "source": [
    "# Create CIS survey '.kmz' files per mile #\n",
    "while j < len(total_miles_list):\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create type folders\n",
    "    while miles_remaining > 0:\n",
    "        # Separate folders by mile\n",
    "        cis_kmz.append(f\"{filtered_data_list[j].split('.csv', 1)[0]} (Mile {current_mile})\")\n",
    "        cis_kmz[i] = simplekml.Kml()\n",
    "\n",
    "        # Separate sub folders by type\n",
    "        type_folders.append(f\"{filtered_data_list[j].split('.csv', 1)[0]} \"\n",
    "                            f\"(Mile {current_mile})(On)\")\n",
    "        type_folders.append(f\"{filtered_data_list[j].split('.csv', 1)[0]} \"\n",
    "                            f\"(Mile {current_mile})(Off)\")\n",
    "        type_folders.append(f\"{filtered_data_list[j].split('.csv', 1)[0]} \"\n",
    "                            f\"(Mile {current_mile})(Comments)\")\n",
    "        type_folders.append(f\"{filtered_data_list[j].split('.csv', 1)[0]} \"\n",
    "                            f\"(Mile {current_mile})(-1.2 V)\")\n",
    "        type_folders.append(f\"{filtered_data_list[j].split('.csv', 1)[0]} \"\n",
    "                            f\"(Mile {current_mile})(-0.85 V)\")\n",
    "        type_folders[k] = cis_kmz[i].newfolder(name='On')\n",
    "        type_folders[k + 1] = cis_kmz[i].newfolder(name='Off')\n",
    "        type_folders[k + 2] = cis_kmz[i].newfolder(name='Comments')\n",
    "        type_folders[k + 3] = cis_kmz[i].newfolder(name='-1.2 V')\n",
    "        type_folders[k + 4] = cis_kmz[i].newfolder(name='-0.85 V')\n",
    "\n",
    "        # Save to file\n",
    "        kmz_name = f\"{filtered_data_list[j].split('.csv', 1)[0]} (Mile {current_mile}).kmz\"\n",
    "        cis_kmz[i].savekmz(os.path.join(root_path, 'Output', kmz_name))\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        i += 1\n",
    "        k += 5\n",
    "\n",
    "    # Counters\n",
    "    j += 1\n",
    "    current_mile = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:30.673339Z",
     "start_time": "2024-04-09T16:23:30.626164Z"
    }
   },
   "id": "484295ba24e627d6",
   "outputs": [],
   "execution_count": 608
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CIS Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6acce1af236c8190"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## On"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19940d4e9c4dc1d4"
  },
  {
   "cell_type": "code",
   "source": [
    "feet_counter = 5280\n",
    "style = simplekml.Style()\n",
    "i = 0  # Loop counter for rows\n",
    "j = 0  # Loop counter for '.csv' files\n",
    "k = 0  # Loop counter for type folders (0 = 'On')\n",
    "kmz_file = 0\n",
    "\n",
    "# Goes through all '.csv' files\n",
    "while j < len(filtered_data_list):\n",
    "    df_cis_on = pd.read_csv(os.path.join(root_path, 'Data', filtered_data_list[j]))\n",
    "    df_cis_on = df_cis_on[df_cis_on['On Potential'] != 0]\n",
    "    df_cis_on = df_cis_on[['Station', 'Stationing (ft)', 'Comments', 'Longitude',\n",
    "                           'Latitude', 'On Potential']].reset_index(drop=True)\n",
    "    df_cis_on['On Potential'] = df_cis_on['On Potential'] * (-1)\n",
    "    last_index = df_cis_on.last_valid_index()\n",
    "    on_measurements = last_index + 1\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create '.kmz' files for each mile #\n",
    "    while miles_remaining > 0:\n",
    "        # Create 3D data points\n",
    "        while i <= last_index and df_cis_on.at[i, 'Station'] < feet_counter:\n",
    "            pnt = type_folders[k].newpoint(name=df_cis_on.at[i, 'On Potential'] * (-1),\n",
    "                                           visibility=DATA_VISIBILITY)\n",
    "            pnt.style.balloonstyle.text = (\n",
    "                f\"Potential: -{df_cis_on.at[i, 'On Potential']} V\\n\"\n",
    "                f\"Longitude: {df_cis_on.at[i, 'Longitude']}\\n\"\n",
    "                f\"Latitude: {df_cis_on.at[i, 'Latitude']}\\n\"\n",
    "                f\"Station (ft): {df_cis_on.at[i, 'Stationing (ft)']}\"\n",
    "            )\n",
    "            pnt.coords = [(df_cis_on.at[i, 'Longitude'], df_cis_on.at[i, 'Latitude'],\n",
    "                           df_cis_on.at[i, 'On Potential'] * SCALE_FACTOR)]\n",
    "            pnt.altitudemode = simplekml.AltitudeMode.relativetoground\n",
    "            pnt.style.iconstyle.icon.href = ICON_ON\n",
    "            pnt.style.iconstyle.scale = ICON_SCALE\n",
    "            pnt.style.labelstyle.scale = 0\n",
    "            pnt.extrude = 0\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        # Save to file\n",
    "        kmz_name = f\"{filtered_data_list[j].split('.csv', 1)[0]} (Mile {current_mile}).kmz\"\n",
    "        cis_kmz[kmz_file].savekmz(os.path.join(output_path, kmz_name))\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        feet_counter += 5280\n",
    "        k += 5\n",
    "        kmz_file += 1\n",
    "\n",
    "    # Counters\n",
    "    feet_counter = 5280\n",
    "    current_mile = 1\n",
    "    i = 0\n",
    "    j += 1\n",
    "\n",
    "# Counters\n",
    "j = 0\n",
    "kmz_file = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:56.410447Z",
     "start_time": "2024-04-09T16:23:30.675497Z"
    }
   },
   "id": "f5518baf9b8f1cb3",
   "outputs": [],
   "execution_count": 609
  },
  {
   "cell_type": "code",
   "source": [
    "# Record duplicate GPS coordinates in a '.csv' file\n",
    "df_duplicates = df_cis_on[df_cis_on.duplicated(subset=['Longitude', 'Latitude'], keep=False)]\n",
    "df_duplicates.to_csv(duplicates_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:23:56.425092Z",
     "start_time": "2024-04-09T16:23:56.411554Z"
    }
   },
   "id": "540a6a3c2da351d",
   "outputs": [],
   "execution_count": 610
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Off"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8ab0b3f4442f8e7"
  },
  {
   "cell_type": "code",
   "source": [
    "k = 1  # Loop counter for type folders (1 = 'Off')\n",
    "off_measurements = 0\n",
    "\n",
    "# Goes through all '.csv' files\n",
    "while j < len(filtered_data_list):\n",
    "    df_cis_off = pd.read_csv(os.path.join(root_path, 'Data', filtered_data_list[j]))\n",
    "    df_cis_off = df_cis_off[df_cis_off['Off Potential'] != 0]\n",
    "    df_cis_off = df_cis_off[['Station', 'Stationing (ft)', 'Longitude', 'Latitude',\n",
    "                             'Off Potential']].reset_index(drop=True)\n",
    "    df_cis_off['Off Potential'] = df_cis_off['Off Potential'] * (-1)\n",
    "    last_index = df_cis_off.last_valid_index()\n",
    "    off_measurements = last_index + 1\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create '.kmz' files for each mile #\n",
    "    while miles_remaining > 0:\n",
    "        # Create 3D data points\n",
    "        while i <= last_index and df_cis_off.at[i, 'Station'] < feet_counter:\n",
    "            # Break loop if there are no 'Off' potentials\n",
    "            if df_cis_off.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            pnt = type_folders[k].newpoint(name=df_cis_off.at[i, 'Off Potential'] * (-1),\n",
    "                                           visibility=DATA_VISIBILITY)\n",
    "            pnt.style.balloonstyle.text = (\n",
    "                f\"Potential: -{df_cis_off.at[i, 'Off Potential']} V\\n\"\n",
    "                f\"Longitude: {df_cis_off.at[i, 'Longitude']}\\n\"\n",
    "                f\"Latitude: {df_cis_off.at[i, 'Latitude']}\\n\"\n",
    "                f\"Station (ft): {df_cis_off.at[i, 'Stationing (ft)']}\"\n",
    "            )\n",
    "            pnt.coords = [(df_cis_off.at[i, 'Longitude'], df_cis_off.at[i, 'Latitude'],\n",
    "                           df_cis_off.at[i, 'Off Potential'] * SCALE_FACTOR)]\n",
    "            pnt.altitudemode = simplekml.AltitudeMode.relativetoground\n",
    "            pnt.style.iconstyle.icon.href = ICON_OFF\n",
    "            pnt.style.iconstyle.scale = ICON_SCALE\n",
    "            pnt.style.linestyle.width = 0.01\n",
    "            pnt.style.linestyle.color = simplekml.Color.rgb(255, 255, 255, round(255 * 0.15))\n",
    "            pnt.style.labelstyle.scale = 0\n",
    "            pnt.extrude = 1\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        # Save to file\n",
    "        kmz_name = f\"{filtered_data_list[j].split('.csv', 1)[0]} (Mile {current_mile}).kmz\"\n",
    "        cis_kmz[kmz_file].savekmz(os.path.join(output_path, kmz_name))\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        feet_counter += 5280\n",
    "        k += 5\n",
    "        kmz_file += 1\n",
    "\n",
    "    # Counters\n",
    "    feet_counter = 5280\n",
    "    current_mile = 1\n",
    "    i = 0\n",
    "    j += 1\n",
    "\n",
    "# Counters\n",
    "j = 0\n",
    "kmz_file = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:24:35.237721Z",
     "start_time": "2024-04-09T16:23:56.426023Z"
    }
   },
   "id": "1156516e922065ef",
   "outputs": [],
   "execution_count": 611
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "818a6aadca1f7a72"
  },
  {
   "cell_type": "code",
   "source": [
    "k = 2  # Loop counter for type folders (2 = 'Comments')\n",
    "\n",
    "# Goes through all '.csv' files\n",
    "while j < len(filtered_data_list):\n",
    "    df_cis_comments = pd.read_csv(os.path.join(root_path, 'Data', filtered_data_list[j]))\n",
    "    df_cis_comments.dropna(inplace=True)\n",
    "    df_cis_comments.reset_index(drop=True, inplace=True)\n",
    "    last_index = df_cis_comments.last_valid_index()\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create '.kmz' files for each mile #\n",
    "    while miles_remaining > 0:\n",
    "        # Create 3D data points\n",
    "        while i <= last_index and df_cis_comments.at[i, 'Station'] < \\\n",
    "                feet_counter:\n",
    "            # Break loop if there are no comments\n",
    "            if df_cis_comments.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            pnt = type_folders[k].newpoint(name=df_cis_comments.at[i, 'Comments'],\n",
    "                                           visibility=DATA_VISIBILITY)\n",
    "\n",
    "            if df_cis_comments.at[i, 'On Potential'] == 0:\n",
    "                potential = df_cis_comments.at[i, 'Off Potential'].__str__() + ' V (Off)'\n",
    "            else:\n",
    "                potential = df_cis_comments.at[i, 'On Potential'].__str__() + ' V (On)'\n",
    "\n",
    "            pnt.style.balloonstyle.text = (\n",
    "                f\"Potential: {potential}\\n\"\n",
    "                f\"Longitude: {df_cis_comments.at[i, 'Longitude']}\\n\"\n",
    "                f\"Latitude: {df_cis_comments.at[i, 'Latitude']}\\n\"\n",
    "                f\"Station (ft): {df_cis_comments.at[i, 'Stationing (ft)']}\\n\"\n",
    "                f\"Comment: {df_cis_comments.at[i, 'Comments']}\"\n",
    "            )\n",
    "            pnt.coords = [(df_cis_comments.at[i, 'Longitude'],\n",
    "                           df_cis_comments.at[i, 'Latitude'], 0)]\n",
    "            pnt.altitudemode = simplekml.AltitudeMode.relativetoground\n",
    "            pnt.style.iconstyle.icon.href = ICON_COMMENTS\n",
    "            pnt.style.iconstyle.scale = ICON_SCALE * 1.5\n",
    "            pnt.style.labelstyle.scale = 0.5\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        # Save to file\n",
    "        kmz_name = f\"{filtered_data_list[j].split('.csv', 1)[0]} (Mile {current_mile}).kmz\"\n",
    "        cis_kmz[kmz_file].savekmz(os.path.join(output_path, kmz_name))\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        feet_counter += 5280\n",
    "        k += 5\n",
    "        kmz_file += 1\n",
    "\n",
    "    # Counters\n",
    "    feet_counter = 5280\n",
    "    current_mile = 1\n",
    "    i = 0\n",
    "    j += 1\n",
    "\n",
    "# Counters\n",
    "j = 0\n",
    "kmz_file = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:25:16.575971Z",
     "start_time": "2024-04-09T16:24:35.238921Z"
    }
   },
   "id": "abdf3743777de556",
   "outputs": [],
   "execution_count": 612
  },
  {
   "cell_type": "markdown",
   "source": [
    "## -1.2 V"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a1751bc186d5651"
  },
  {
   "cell_type": "code",
   "source": [
    "k = 3  # Loop counter for type folders (3 = '-1.2 V')\n",
    "\n",
    "# Goes through all '.csv' files\n",
    "while j < len(filtered_data_list):\n",
    "    df_cis_1200 = pd.read_csv(os.path.join(root_path, 'Data', filtered_data_list[j]))\n",
    "    last_index = df_cis_1200.last_valid_index()\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create '.kmz' files for each mile #\n",
    "    while miles_remaining > 0:\n",
    "        # Create 3D data points\n",
    "        while i <= last_index and df_cis_1200.at[i, 'Station'] < feet_counter:\n",
    "            pnt = type_folders[k].newpoint(name='-1.200', visibility=DATA_VISIBILITY)\n",
    "            pnt.style.balloonstyle.text = 'Potential: -1.2 V'\n",
    "            pnt.coords = [(df_cis_1200.at[i, 'Longitude'], df_cis_1200.at[i, 'Latitude'],\n",
    "                           1.2 * SCALE_FACTOR)]\n",
    "            pnt.altitudemode = simplekml.AltitudeMode.relativetoground\n",
    "            pnt.style.iconstyle.icon.href = ICON_1200\n",
    "            pnt.style.iconstyle.scale = ICON_SCALE\n",
    "            pnt.style.labelstyle.scale = 0\n",
    "            pnt.extrude = 0\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        # Save to file\n",
    "        kmz_name = f\"{filtered_data_list[j].split('.csv', 1)[0]} (Mile {current_mile}).kmz\"\n",
    "        cis_kmz[kmz_file].savekmz(os.path.join(output_path, kmz_name))\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        feet_counter += 5280\n",
    "        k += 5\n",
    "        kmz_file += 1\n",
    "\n",
    "    # Counters\n",
    "    feet_counter = 5280\n",
    "    current_mile = 1\n",
    "    i = 0\n",
    "    j += 1\n",
    "\n",
    "# Counters\n",
    "j = 0\n",
    "kmz_file = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:26:13.193503Z",
     "start_time": "2024-04-09T16:25:16.577179Z"
    }
   },
   "id": "5cde780ff8eff497",
   "outputs": [],
   "execution_count": 613
  },
  {
   "cell_type": "markdown",
   "source": [
    "## -0.85 V"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58de2af4e8e215a3"
  },
  {
   "cell_type": "code",
   "source": [
    "k = 4  # Loop counter for type folders (4 = '-0.85 V')\n",
    "\n",
    "# Goes through all '.csv' files\n",
    "while j < len(filtered_data_list):\n",
    "    df_cis_850 = pd.read_csv(os.path.join(root_path, 'Data', filtered_data_list[j]))\n",
    "    last_index = df_cis_850.last_valid_index()\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create '.kmz' files for each mile #\n",
    "    while miles_remaining > 0:\n",
    "        # Create 3D data points\n",
    "        while i <= last_index and df_cis_850.at[i, 'Station'] < feet_counter:\n",
    "            pnt = type_folders[k].newpoint(name='-0.850', visibility=DATA_VISIBILITY)\n",
    "            pnt.style.balloonstyle.text = 'Potential: -0.85 V'\n",
    "            pnt.coords = [(df_cis_850.at[i, 'Longitude'], df_cis_850.at[i, 'Latitude'],\n",
    "                           0.85 * SCALE_FACTOR)]\n",
    "            pnt.altitudemode = simplekml.AltitudeMode.relativetoground\n",
    "            pnt.style.iconstyle.icon.href = ICON_850\n",
    "            pnt.style.iconstyle.scale = ICON_SCALE\n",
    "            pnt.style.labelstyle.scale = 0\n",
    "            pnt.extrude = 0\n",
    "            pnt.style.linestyle.width = 0.01\n",
    "            pnt.style.linestyle.color = simplekml.Color.rgb(255, 255, 255, round(255 * 0.15))\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        # Save to file\n",
    "        kmz_name = f\"{filtered_data_list[j].split('.csv', 1)[0]} (Mile {current_mile}).kmz\"\n",
    "        cis_kmz[kmz_file].savekmz(os.path.join(output_path, kmz_name))\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        feet_counter += 5280\n",
    "        k += 5\n",
    "        kmz_file += 1\n",
    "\n",
    "    # Counters\n",
    "    feet_counter = 5280\n",
    "    current_mile = 1\n",
    "    i = 0\n",
    "    j += 1\n",
    "\n",
    "# Counters\n",
    "j = 0\n",
    "kmz_file = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:40.269349Z",
     "start_time": "2024-04-09T16:26:13.194668Z"
    }
   },
   "id": "7898ce1607c10d0b",
   "outputs": [],
   "execution_count": 614
  },
  {
   "cell_type": "markdown",
   "source": "## Assign Station Numbers to KMZs",
   "metadata": {
    "collapsed": false
   },
   "id": "29f0433ee3d1e227"
  },
  {
   "cell_type": "code",
   "source": [
    "sn_list = [''] * (math.ceil(total_miles_list[0]) * 2)\n",
    "name_list = [''] * (math.ceil(total_miles_list[0]) + 1)\n",
    "station_list = np.arange(0, math.ceil(total_miles_list[0]) + 1)\n",
    "last_index_station = len(station_list) - 1\n",
    "last_index_sn = len(sn_list) - 1\n",
    "station_list[0] = starting_stationing"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:40.279022Z",
     "start_time": "2024-04-09T16:27:40.274370Z"
    }
   },
   "id": "f0230805d7c09f0",
   "outputs": [],
   "execution_count": 615
  },
  {
   "cell_type": "code",
   "source": [
    "# Assign a value of mile (ft) per element\n",
    "for i in range(1, last_index_station + 1):\n",
    "    station_list[i] = station_list[i - 1] + 5280\n",
    "\n",
    "# Last row\n",
    "station_list[last_index_station] = math.ceil(\n",
    "    ((total_miles_list[0] - last_index_station + 3) * 5280 + station_list[last_index_station - 1]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:40.284708Z",
     "start_time": "2024-04-09T16:27:40.280476Z"
    }
   },
   "id": "ee938f4f2e3ec7b9",
   "outputs": [],
   "execution_count": 616
  },
  {
   "cell_type": "code",
   "source": [
    "# First SN\n",
    "closest_index = (df_cis['Station'] + starting_stationing - station_list[0]).abs().argmin()\n",
    "sn_list[0] = f\"SN{df_cis['Stationing (ft)'].loc[closest_index]}\".replace(' ', '')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:40.303807Z",
     "start_time": "2024-04-09T16:27:40.285540Z"
    }
   },
   "id": "d72bec8f2fface08",
   "outputs": [],
   "execution_count": 617
  },
  {
   "cell_type": "code",
   "source": [
    "j = 1  # station_list counter\n",
    "i = 1  # sn_list counter\n",
    "\n",
    "# In between SN\n",
    "while i < last_index_sn:\n",
    "    closest_index = (df_cis['Station'] + starting_stationing - station_list[j]).abs().argmin()\n",
    "\n",
    "    if df_cis['Station'].loc[closest_index] - station_list[j] >= 0:\n",
    "        # Below closest index\n",
    "        sn_list[i] = f\"SN{df_cis['Stationing (ft)'].loc[closest_index - 1]}\".replace(' ', '')\n",
    "        sn_list[i + 1] = f\"SN{df_cis['Stationing (ft)'].loc[closest_index]}\".replace(' ', '')\n",
    "\n",
    "    else:\n",
    "        # Above closest index\n",
    "        sn_list[i] = f\"SN{df_cis['Stationing (ft)'].loc[closest_index]}\".replace(' ', '')\n",
    "        sn_list[i + 1] = f\"SN{df_cis['Stationing (ft)'].loc[closest_index + 1]}\".replace(' ', '')\n",
    "\n",
    "    # Counters\n",
    "    j += 1\n",
    "    i += 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:40.322206Z",
     "start_time": "2024-04-09T16:27:40.305190Z"
    }
   },
   "id": "889f994c08ec6784",
   "outputs": [],
   "execution_count": 618
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:40.326597Z",
     "start_time": "2024-04-09T16:27:40.323287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Last SN\n",
    "closest_index = (df_cis['Station'] + starting_stationing -\n",
    "                 station_list[last_index_station]).abs().argmin()\n",
    "sn_list[last_index_sn] = f\"SN{df_cis['Stationing (ft)'].loc[closest_index]}\".replace(' ', '')"
   ],
   "id": "1296daf934907408",
   "outputs": [],
   "execution_count": 619
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:40.334473Z",
     "start_time": "2024-04-09T16:27:40.327405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Log\n",
    "with open(log_path, 'a') as f:\n",
    "    f.write('Removed files:')\n",
    "\n",
    "# Remove files below certain size\n",
    "for filename in os.listdir(output_path):\n",
    "    file_path = os.path.join(output_path, filename)\n",
    "    # Get file size in bytes\n",
    "    size = os.path.getsize(file_path)\n",
    "\n",
    "    # If size < 1 KB, remove file\n",
    "    if size < 1024 and filename != 'Log.txt':\n",
    "        os.remove(file_path)\n",
    "        with open(log_path, 'a') as f:\n",
    "            f.write(f'\\n- {filename}')"
   ],
   "id": "9f5e5cc99b52a6a8",
   "outputs": [],
   "execution_count": 620
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:40.338040Z",
     "start_time": "2024-04-09T16:27:40.335763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove duplicate SNs\n",
    "sn_list = list(OrderedDict.fromkeys(sn_list))\n",
    "\n",
    "# Get new index\n",
    "last_index_sn = len(sn_list) - 1"
   ],
   "id": "4c16c1a610c07eca",
   "outputs": [],
   "execution_count": 621
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:40.354135Z",
     "start_time": "2024-04-09T16:27:40.339147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sort kmz files\n",
    "kmz_files = glob.glob(os.path.join(output_path, '*.kmz'))\n",
    "kmz_files = [os.path.basename(file) for file in kmz_files]\n",
    "kmz_files = natsorted(kmz_files)"
   ],
   "id": "64438f649dc8814a",
   "outputs": [],
   "execution_count": 622
  },
  {
   "cell_type": "code",
   "source": [
    "j = 0  # sn_list counter\n",
    "\n",
    "# Name station number ranges\n",
    "for i in range(0, last_index_station - 1):\n",
    "    name_list[i] = (f\"{filtered_data_list[0].split('SN')[0][:-1]} \"\n",
    "                    f\"({sn_list[j]} TO {sn_list[j + 1]}).kmz\")\n",
    "    j += 2\n",
    "\n",
    "# Rename '.kmz' files\n",
    "for i in range(0, last_index_station - 1):\n",
    "    os.rename(os.path.join(output_path, kmz_files[i]), os.path.join(output_path, name_list[i]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:40.374571Z",
     "start_time": "2024-04-09T16:27:40.363939Z"
    }
   },
   "id": "741627bad1267d71",
   "outputs": [],
   "execution_count": 623
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Areas of Interest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dddd93b34554179"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Add to exception report when Off is more negative than On\n",
    "# TODO: Add to exception report where skips exist\n",
    "# TODO: Add to exception report between TS"
   ],
   "id": "f10fb009cc63b265"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Less Negative than -0.85V \"On\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7ded736fc7c9708"
  },
  {
   "cell_type": "code",
   "source": [
    "# Combines all '.csv' files in folder\n",
    "df_cis_filtered = pd.concat(\n",
    "    (pd.read_csv(f) for f in glob.glob(os.path.join(data_path, r'*.csv'))),\n",
    "    ignore_index=True\n",
    ")\n",
    "df_cis_filtered = df_cis_filtered[df_cis_filtered['On Potential'] != 0]\n",
    "df_cis_filtered = df_cis_filtered[['Station', 'Stationing (ft)', 'Longitude', 'Latitude',\n",
    "                                   'On Potential']].reset_index(drop=True)\n",
    "df_cis_filtered['Crossing Point'] = ''\n",
    "last_index = df_cis_filtered.last_valid_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:40.572007Z",
     "start_time": "2024-04-09T16:27:40.375861Z"
    }
   },
   "id": "d201b6c3f7a23dec",
   "outputs": [],
   "execution_count": 624
  },
  {
   "cell_type": "code",
   "source": [
    "i = 1  # Loop counter for rows\n",
    "\n",
    "if df_cis_filtered.shape[0] != 0:\n",
    "    # Finds crossing points\n",
    "    while i < last_index:\n",
    "        # First data point\n",
    "        if i == 1 and df_cis_filtered.at[0, 'On Potential'] >= -0.85:\n",
    "            df_cis_filtered.at[0, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # Second data point\n",
    "        elif i == 2 and df_cis_filtered.at[1, 'On Potential'] >= -0.85:\n",
    "            df_cis_filtered.at[0, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # Last data point\n",
    "        elif (i == last_index - 1 and\n",
    "              df_cis_filtered.at[last_index, 'On Potential'] >= -0.85):\n",
    "            df_cis_filtered.at[last_index, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # _'_\n",
    "        elif ((df_cis_filtered.at[i - 1, 'On Potential'] > -0.85) and\n",
    "              (df_cis_filtered.at[i, 'On Potential'] <= -0.85) and\n",
    "              (df_cis_filtered.at[i + 1, 'On Potential'] > -0.85) and\n",
    "              i >= 1):\n",
    "            df_cis_filtered.at[i, 'Crossing Point'] = 'XX'\n",
    "\n",
    "        # '_\n",
    "        elif ((df_cis_filtered.at[i + 1, 'On Potential'] > -0.85) and\n",
    "              (df_cis_filtered.at[i, 'On Potential'] <= -0.85)):\n",
    "            df_cis_filtered.at[i, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # _'\n",
    "        elif ((df_cis_filtered.at[i + 1, 'On Potential'] < -0.85) and\n",
    "              (df_cis_filtered.at[i, 'On Potential'] >= -0.85)):\n",
    "            df_cis_filtered.at[i + 1, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    # Drops rows that are empty\n",
    "    df_cis_filtered = (df_cis_filtered[df_cis_filtered['Crossing Point'] != '']\n",
    "                       .reset_index(drop=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:41.139619Z",
     "start_time": "2024-04-09T16:27:40.573082Z"
    }
   },
   "id": "c6e2d556a270a090",
   "outputs": [],
   "execution_count": 625
  },
  {
   "cell_type": "code",
   "source": [
    "if df_cis_filtered.shape[0] != 0:\n",
    "    # Replicates rows that have 'XX'\n",
    "    df_cis_filtered = df_cis_filtered.loc[df_cis_filtered.index\n",
    "    .repeat(df_cis_filtered['Crossing Point'].isin(['XX']).add(1))].reset_index(drop=True)\n",
    "    last_index = int((df_cis_filtered.last_valid_index() + 1) / 2)\n",
    "\n",
    "    # Create report dataframe\n",
    "    df_cis_report = pd.DataFrame(\n",
    "        index=np.arange(last_index),\n",
    "        columns=['Station', 'Station Number', 'Latitude', 'Longitude',\n",
    "                 'Station', 'Station Number', 'Latitude', 'Longitude']\n",
    "    )\n",
    "    df_cis_report['Length (ft)'] = 0.0\n",
    "    df_cis_report['Comments'] = ''\n",
    "\n",
    "    # Counters\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    # Structure data\n",
    "    while j < int((df_cis_filtered.last_valid_index() + 1) / 2):\n",
    "        # Start\n",
    "        df_cis_report.iat[j, 0] = df_cis_filtered.at[i, 'Station']\n",
    "        df_cis_report.iat[j, 1] = df_cis_filtered.at[i, 'Stationing (ft)']\n",
    "        df_cis_report.iat[j, 2] = df_cis_filtered.at[i, 'Latitude']\n",
    "        df_cis_report.iat[j, 3] = df_cis_filtered.at[i, 'Longitude']\n",
    "\n",
    "        # End\n",
    "        df_cis_report.iat[j, 4] = df_cis_filtered.at[i + 1, 'Station']\n",
    "        df_cis_report.iat[j, 5] = df_cis_filtered.at[i + 1, 'Stationing (ft)']\n",
    "        df_cis_report.iat[j, 6] = df_cis_filtered.at[i + 1, 'Latitude']\n",
    "        df_cis_report.iat[j, 7] = df_cis_filtered.at[i + 1, 'Longitude']\n",
    "\n",
    "        # Length\n",
    "        df_cis_report.iat[j, 8] = df_cis_report.iat[j, 4] - df_cis_report.iat[j, 0]\n",
    "\n",
    "        # Counters\n",
    "        j += 1\n",
    "        i += 2\n",
    "\n",
    "    # Deletes station columns\n",
    "    df_cis_report = df_cis_report.drop(df_cis_report.iloc[:, [0, 4]], axis=1)\n",
    "\n",
    "    # Save to file\n",
    "    excel_name = f\"CIS Exception Report ({filtered_data_list[0].split('.csv')[0]}).xlsx\"\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(output_path, excel_name),\n",
    "                        mode='w', engine='openpyxl') as writer:\n",
    "        df_cis_report.to_excel(writer, startrow=4,\n",
    "                               sheet_name='Less Negative than -0.85V (On)',\n",
    "                               index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:41.229379Z",
     "start_time": "2024-04-09T16:27:41.140560Z"
    }
   },
   "id": "831f659f626c5ada",
   "outputs": [],
   "execution_count": 626
  },
  {
   "cell_type": "code",
   "source": [
    "if df_cis_filtered.shape[0] != 0:\n",
    "    wb = load_workbook(os.path.join(output_path, excel_name))\n",
    "    sheet = wb['Less Negative than -0.85V (On)']\n",
    "    # Company name with pipeline ID\n",
    "    sheet.cell(1, 1).value = f\"{client} ({filtered_data_list[0].split('SN')[0][:-1]})\"\n",
    "\n",
    "    # Station numbers surveyed\n",
    "    sheet.cell(2, 1).value = (\n",
    "        f\"{filtered_data_list[0].split('SN')[1].split()[0]} to \"\n",
    "        f\"{filtered_data_list[0].split('SN')[2].split('.')[0]}\"\n",
    "    )\n",
    "\n",
    "    # Start\n",
    "    sheet.cell(4, 1).value = 'Start'\n",
    "\n",
    "    # End\n",
    "    sheet.cell(4, 4).value = 'End'\n",
    "\n",
    "    # Total pipeline distance with issues\n",
    "    total_feet = round(sum(total_miles_list * 5280))\n",
    "    total_miles = round(sum(total_miles_list), 2)\n",
    "    sheet.cell(last_index + 7, 1).value = (\n",
    "        f\"Total pipeline distance surveyed = {total_feet} feet or {total_miles} miles\"\n",
    "    )\n",
    "    total_length = df_cis_report['Length (ft)'].sum()\n",
    "    length_percent = round(total_length / sum(total_miles_list * 5280) * 100, 2)\n",
    "    sheet.cell(last_index + 8, 1).value = (\n",
    "        f\"Total pipeline distance less negative than -0.85V 'On' = \"\n",
    "        f\"{total_length} feet ({length_percent} %)\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:41.270614Z",
     "start_time": "2024-04-09T16:27:41.230388Z"
    }
   },
   "id": "252a3e0e42c540f6",
   "outputs": [],
   "execution_count": 627
  },
  {
   "cell_type": "code",
   "source": [
    "if df_cis_filtered.shape[0] != 0:\n",
    "    # Font\n",
    "    sheet.cell(1, 1).font = Font(size=14, bold=True)\n",
    "    sheet.cell(2, 1).font = Font(italic=True)\n",
    "    sheet.cell(4, 1).font = Font(bold=True)\n",
    "    sheet.cell(4, 4).font = Font(bold=True)\n",
    "    sheet.cell(4, 7).font = Font(bold=True)\n",
    "    sheet.cell(4, 8).font = Font(bold=True)\n",
    "    sheet.cell(last_index + 7, 1).font = Font(bold=True)\n",
    "    sheet.cell(last_index + 8, 1).font = Font(bold=True)\n",
    "\n",
    "    # Merging\n",
    "    sheet.merge_cells('A1:H1')\n",
    "    sheet.merge_cells('A2:H2')\n",
    "    sheet.merge_cells('A4:C4')\n",
    "    sheet.merge_cells('D4:F4')\n",
    "    sheet.cell(4, 7).value = sheet.cell(5, 7).value\n",
    "    sheet.merge_cells('G4:G5')\n",
    "    sheet.cell(4, 8).value = sheet.cell(5, 8).value\n",
    "    sheet.merge_cells('H4:H5')\n",
    "\n",
    "    # Alignment\n",
    "    i = 0\n",
    "\n",
    "    while i < (last_index + 5):\n",
    "        for c in sheet['A1:H' + str(last_index + 5)][i]:\n",
    "            c.alignment = Alignment(horizontal='center', vertical='center')\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    # Borders\n",
    "    i = 0\n",
    "    thin = Side(border_style='thin', color='000000')\n",
    "    white_border = Side(border_style='thin', color='FFFFFF')\n",
    "\n",
    "    while i < (last_index + 5):\n",
    "        # 3rd row\n",
    "        if i == 2:\n",
    "            for c in sheet['A1:H' + str(last_index + 5)][i]:\n",
    "                c.border = Border(left=white_border, right=white_border)\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        for c in sheet['A1:H' + str(last_index + 5)][i]:\n",
    "            c.border = Border(top=thin, left=thin, right=thin, bottom=thin)\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    # Column widths\n",
    "    for col in 'ABCDEFG':\n",
    "        sheet.column_dimensions[col].width = 15\n",
    "\n",
    "    sheet.column_dimensions['H'].width = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:41.569811Z",
     "start_time": "2024-04-09T16:27:41.272512Z"
    }
   },
   "id": "a965671e30ee65eb",
   "outputs": [],
   "execution_count": 628
  },
  {
   "cell_type": "code",
   "source": [
    "# Save to excel\n",
    "if df_cis_filtered.shape[0] != 0:\n",
    "    wb.save(os.path.join(output_path, excel_name))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:41.595226Z",
     "start_time": "2024-04-09T16:27:41.571459Z"
    }
   },
   "id": "c8c043b006ffe978",
   "outputs": [],
   "execution_count": 629
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Less Negative than -0.85V \"Off\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44fcf58163fa0d80"
  },
  {
   "cell_type": "code",
   "source": [
    "# Combines all '.csv' files at specified folder\n",
    "df_cis_filtered = pd.concat(\n",
    "    (pd.read_csv(f) for f in glob.glob(os.path.join(data_path, r'*.csv'))),\n",
    "    ignore_index=True\n",
    ")\n",
    "df_cis_filtered = df_cis_filtered[df_cis_filtered['Off Potential'] != 0]\n",
    "df_cis_filtered = df_cis_filtered[['Station', 'Stationing (ft)', 'Longitude',\n",
    "                                   'Latitude', 'Off Potential']].reset_index(drop=True)\n",
    "df_cis_filtered['Crossing Point'] = ''\n",
    "last_index = df_cis_filtered.last_valid_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:41.697126Z",
     "start_time": "2024-04-09T16:27:41.597056Z"
    }
   },
   "id": "57b67e8b22be019e",
   "outputs": [],
   "execution_count": 630
  },
  {
   "cell_type": "code",
   "source": [
    "i = 1  # Loop counter for rows\n",
    "\n",
    "if df_cis_filtered.shape[0] != 0:\n",
    "    # Finds crossing points\n",
    "    while i < last_index:\n",
    "        # First data point\n",
    "        if i == 1 and df_cis_filtered.at[0, 'Off Potential'] >= -0.85:\n",
    "            df_cis_filtered.at[0, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # Second data point\n",
    "        elif i == 2 and df_cis_filtered.at[1, 'Off Potential'] >= -0.85:\n",
    "            df_cis_filtered.at[0, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # Last data point\n",
    "        elif (i == last_index - 1 and\n",
    "              df_cis_filtered.at[last_index, 'Off Potential'] >= -0.85):\n",
    "            df_cis_filtered.at[last_index, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # _'_\n",
    "        elif ((df_cis_filtered.at[i - 1, 'Off Potential'] > -0.85) and\n",
    "              (df_cis_filtered.at[i, 'Off Potential'] <= -0.85) and\n",
    "              (df_cis_filtered.at[i + 1, 'Off Potential'] > -0.85) and\n",
    "              i >= 1):\n",
    "            df_cis_filtered.at[i, 'Crossing Point'] = 'XX'\n",
    "\n",
    "        # '_\n",
    "        elif ((df_cis_filtered.at[i + 1, 'Off Potential'] > -0.85) and\n",
    "              (df_cis_filtered.at[i, 'Off Potential'] <= -0.85)):\n",
    "            df_cis_filtered.at[i, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # _'\n",
    "        elif ((df_cis_filtered.at[i + 1, 'Off Potential'] < -0.85) and\n",
    "              (df_cis_filtered.at[i, 'Off Potential'] >= -0.85)):\n",
    "            df_cis_filtered.at[i + 1, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    df_cis_filtered = (df_cis_filtered[df_cis_filtered['Crossing Point'] != '']\n",
    "                       .reset_index(drop=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:42.375573Z",
     "start_time": "2024-04-09T16:27:41.698426Z"
    }
   },
   "id": "5eb86beaea52d12e",
   "outputs": [],
   "execution_count": 631
  },
  {
   "cell_type": "code",
   "source": [
    "if df_cis_filtered.shape[0] != 0:\n",
    "    # Replicates rows that have 'XX'\n",
    "    df_cis_filtered = df_cis_filtered.loc[df_cis_filtered.index\n",
    "    .repeat(df_cis_filtered['Crossing Point'].isin(['XX']).add(1))].reset_index(drop=True)\n",
    "    last_index = int((df_cis_filtered.last_valid_index() + 1) / 2)\n",
    "\n",
    "    # Create report dataframe\n",
    "    df_cis_report = pd.DataFrame(\n",
    "        index=np.arange(last_index),\n",
    "        columns=['Station', 'Station Number', 'Latitude', 'Longitude',\n",
    "                 'Station', 'Station Number', 'Latitude', 'Longitude']\n",
    "    )\n",
    "    df_cis_report['Length (ft)'] = 0.0\n",
    "    df_cis_report['Comments'] = ''\n",
    "\n",
    "    # Counters\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    # Structure data\n",
    "    while j < int((df_cis_filtered.last_valid_index() + 1) / 2):\n",
    "        # Start\n",
    "        df_cis_report.iat[j, 0] = df_cis_filtered.at[i, 'Station']\n",
    "        df_cis_report.iat[j, 1] = df_cis_filtered.at[i, 'Stationing (ft)']\n",
    "        df_cis_report.iat[j, 2] = df_cis_filtered.at[i, 'Latitude']\n",
    "        df_cis_report.iat[j, 3] = df_cis_filtered.at[i, 'Longitude']\n",
    "\n",
    "        # End\n",
    "        df_cis_report.iat[j, 4] = df_cis_filtered.at[i + 1, 'Station']\n",
    "        df_cis_report.iat[j, 5] = df_cis_filtered.at[i + 1, 'Stationing (ft)']\n",
    "        df_cis_report.iat[j, 6] = df_cis_filtered.at[i + 1, 'Latitude']\n",
    "        df_cis_report.iat[j, 7] = df_cis_filtered.at[i + 1, 'Longitude']\n",
    "\n",
    "        # Length\n",
    "        df_cis_report.iat[j, 8] = df_cis_report.iat[j, 4] - df_cis_report.iat[j, 0]\n",
    "\n",
    "        # Counters\n",
    "        j += 1\n",
    "        i += 2\n",
    "\n",
    "    # Deletes station columns\n",
    "    df_cis_report = df_cis_report.drop(df_cis_report.iloc[:, [0, 4]], axis=1)\n",
    "\n",
    "    # Save to file\n",
    "    # Save to file\n",
    "    excel_name = f\"CIS Exception Report ({filtered_data_list[0].split('.csv')[0]}).xlsx\"\n",
    "    writing_mode = 'w'\n",
    "\n",
    "    if os.path.exists(os.path.join(output_path, excel_name)):\n",
    "        writing_mode = 'a'\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(output_path, excel_name),\n",
    "                        mode=writing_mode, engine='openpyxl') as writer:\n",
    "        df_cis_report.to_excel(writer, startrow=4,\n",
    "                               sheet_name='Less Negative than -0.85V (Off)',\n",
    "                               index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:42.466230Z",
     "start_time": "2024-04-09T16:27:42.376779Z"
    }
   },
   "id": "5d6edcd7a3629a55",
   "outputs": [],
   "execution_count": 632
  },
  {
   "cell_type": "code",
   "source": [
    "if df_cis_filtered.shape[0] != 0:\n",
    "    wb = load_workbook(os.path.join(output_path, excel_name))\n",
    "    sheet = wb['Less Negative than -0.85V (Off)']\n",
    "\n",
    "    # Company name with pipeline ID\n",
    "    sheet.cell(1, 1).value = f\"{client} ({filtered_data_list[0].split('SN')[0][:-1]})\"\n",
    "\n",
    "    # Station numbers surveyed\n",
    "    sheet.cell(2, 1).value = (\n",
    "        f\"{filtered_data_list[0].split('SN')[1].split()[0]} to \"\n",
    "        f\"{filtered_data_list[0].split('SN')[2].split('.')[0]}\"\n",
    "    )\n",
    "\n",
    "    # Start\n",
    "    sheet.cell(4, 1).value = 'Start'\n",
    "\n",
    "    # End\n",
    "    sheet.cell(4, 4).value = 'End'\n",
    "\n",
    "    # Total pipeline distance with issues\n",
    "    total_feet = round(sum(total_miles_list * 5280))\n",
    "    total_miles = round(sum(total_miles_list), 2)\n",
    "    sheet.cell(last_index + 7, 1).value = (\n",
    "        f\"Total pipeline distance surveyed = {total_feet} feet or {total_miles} miles\"\n",
    "    )\n",
    "    total_length = df_cis_report['Length (ft)'].sum()\n",
    "    length_percent = round(total_length / sum(total_miles_list * 5280) * 100, 2)\n",
    "    sheet.cell(last_index + 8, 1).value = (\n",
    "        f\"Total pipeline distance less negative than -0.85V 'Off' = \"\n",
    "        f\"{total_length} feet ({length_percent} %)\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:42.508093Z",
     "start_time": "2024-04-09T16:27:42.472225Z"
    }
   },
   "id": "fbe019e2b01a1d30",
   "outputs": [],
   "execution_count": 633
  },
  {
   "cell_type": "code",
   "source": [
    "if df_cis_filtered.shape[0] != 0:\n",
    "    # Font\n",
    "    sheet.cell(1, 1).font = Font(size=14, bold=True)\n",
    "    sheet.cell(2, 1).font = Font(italic=True)\n",
    "    sheet.cell(4, 1).font = Font(bold=True)\n",
    "    sheet.cell(4, 4).font = Font(bold=True)\n",
    "    sheet.cell(4, 7).font = Font(bold=True)\n",
    "    sheet.cell(4, 8).font = Font(bold=True)\n",
    "    sheet.cell(last_index + 7, 1).font = Font(bold=True)\n",
    "    sheet.cell(last_index + 8, 1).font = Font(bold=True)\n",
    "\n",
    "    # Merging\n",
    "    sheet.merge_cells('A1:H1')\n",
    "    sheet.merge_cells('A2:H2')\n",
    "    sheet.merge_cells('A4:C4')\n",
    "    sheet.merge_cells('D4:F4')\n",
    "    sheet.cell(4, 7).value = sheet.cell(5, 7).value\n",
    "    sheet.merge_cells('G4:G5')\n",
    "    sheet.cell(4, 8).value = sheet.cell(5, 8).value\n",
    "    sheet.merge_cells('H4:H5')\n",
    "\n",
    "    # Alignment\n",
    "    i = 0\n",
    "\n",
    "    while i < (last_index + 5):\n",
    "        for c in sheet['A1:H' + str(last_index + 5)][i]:\n",
    "            c.alignment = Alignment(horizontal='center', vertical='center')\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    # Borders\n",
    "    i = 0\n",
    "    thin = Side(border_style='thin', color='000000')\n",
    "    white_border = Side(border_style='thin', color='FFFFFF')\n",
    "\n",
    "    while i < (last_index + 5):\n",
    "        # 3rd row\n",
    "        if i == 2:\n",
    "            for c in sheet['A1:H' + str(last_index + 5)][i]:\n",
    "                c.border = Border(left=white_border, right=white_border)\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        for c in sheet['A1:H' + str(last_index + 5)][i]:\n",
    "            c.border = Border(top=thin, left=thin, right=thin, bottom=thin)\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    # Column widths\n",
    "    for col in 'ABCDEFG':\n",
    "        sheet.column_dimensions[col].width = 15\n",
    "\n",
    "    sheet.column_dimensions['H'].width = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:42.815284Z",
     "start_time": "2024-04-09T16:27:42.509074Z"
    }
   },
   "id": "dac95354c3e1d9f2",
   "outputs": [],
   "execution_count": 634
  },
  {
   "cell_type": "code",
   "source": [
    "# Save to excel\n",
    "if df_cis_filtered.shape[0] != 0:\n",
    "    wb.save(os.path.join(output_path, excel_name))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:42.841680Z",
     "start_time": "2024-04-09T16:27:42.816401Z"
    }
   },
   "id": "55842f4fe929e5f9",
   "outputs": [],
   "execution_count": 635
  },
  {
   "cell_type": "markdown",
   "source": [
    "## More Negative than -1.2V \"Off\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d534a06aab892b"
  },
  {
   "cell_type": "code",
   "source": [
    "# Combines all '.csv' files at specified folder\n",
    "df_cis_filtered = pd.concat(\n",
    "    (pd.read_csv(f) for f in glob.glob(os.path.join(data_path, r'*.csv'))),\n",
    "    ignore_index=True\n",
    ")\n",
    "df_cis_filtered = df_cis_filtered[df_cis_filtered['Off Potential'] != 0]\n",
    "df_cis_filtered = df_cis_filtered[['Station', 'Stationing (ft)', 'Longitude', 'Latitude',\n",
    "                                   'Off Potential']].reset_index(drop=True)\n",
    "df_cis_filtered['Crossing Point'] = ''\n",
    "last_index = df_cis_filtered.last_valid_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:42.925280Z",
     "start_time": "2024-04-09T16:27:42.843138Z"
    }
   },
   "id": "7beee1bd54415c20",
   "outputs": [],
   "execution_count": 636
  },
  {
   "cell_type": "code",
   "source": [
    "i = 1  # Loop counter for rows\n",
    "\n",
    "# Finds crossing points\n",
    "if df_cis_filtered.shape[0] != 0:\n",
    "    while i < last_index:\n",
    "        # First data point\n",
    "        if i == 1 and df_cis_filtered.at[0, 'Off Potential'] <= -1.2:\n",
    "            df_cis_filtered.at[0, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # Second data point\n",
    "        elif i == 2 and df_cis_filtered.at[1, 'Off Potential'] <= -1.2:\n",
    "            df_cis_filtered.at[0, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # Last data point\n",
    "        elif (i == last_index - 1 and\n",
    "              df_cis_filtered.at[last_index, 'Off Potential'] <= -1.2):\n",
    "            df_cis_filtered.at[last_index, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # '_'\n",
    "        elif ((df_cis_filtered.at[i - 1, 'Off Potential'] < -1.2) and\n",
    "              (df_cis_filtered.at[i, 'Off Potential'] >= -1.2) and\n",
    "              (df_cis_filtered.at[i + 1, 'Off Potential'] < -1.2) and\n",
    "              i >= 1):\n",
    "            df_cis_filtered.at[i, 'Crossing Point'] = 'XX'\n",
    "\n",
    "        # '_\n",
    "        elif ((df_cis_filtered.at[i + 1, 'Off Potential'] > -1.2) and\n",
    "              (df_cis_filtered.at[i, 'Off Potential'] <= -1.2)):\n",
    "            df_cis_filtered.at[i + 1, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # _'\n",
    "        elif ((df_cis_filtered.at[i + 1, 'Off Potential'] < -1.2) and\n",
    "              (df_cis_filtered.at[i, 'Off Potential'] >= -1.2)):\n",
    "            df_cis_filtered.at[i, 'Crossing Point'] = 'X'\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    df_cis_filtered = (df_cis_filtered[df_cis_filtered['Crossing Point'] != '']\n",
    "                       .reset_index(drop=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:43.480838Z",
     "start_time": "2024-04-09T16:27:42.926493Z"
    }
   },
   "id": "6c297ce98da79212",
   "outputs": [],
   "execution_count": 637
  },
  {
   "cell_type": "code",
   "source": [
    "if df_cis_filtered.shape[0] != 0:\n",
    "    # Replicates rows that have 'XX'\n",
    "    df_cis_filtered = df_cis_filtered.loc[df_cis_filtered.index\n",
    "    .repeat(df_cis_filtered['Crossing Point'].isin(['XX']).add(1))].reset_index(drop=True)\n",
    "    last_index = int((df_cis_filtered.last_valid_index() + 1) / 2)\n",
    "\n",
    "    # Create report dataframe\n",
    "    df_cis_report = pd.DataFrame(\n",
    "        index=np.arange(last_index),\n",
    "        columns=['Station', 'Station Number', 'Latitude', 'Longitude',\n",
    "                 'Station', 'Station Number', 'Latitude', 'Longitude']\n",
    "    )\n",
    "    df_cis_report['Length (ft)'] = 0.0\n",
    "    df_cis_report['Comments'] = ''\n",
    "\n",
    "    # Counters\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    # Structure data\n",
    "    while j < int((df_cis_filtered.last_valid_index() + 1) / 2):\n",
    "        # Start\n",
    "        df_cis_report.iat[j, 0] = df_cis_filtered.at[i, 'Station']\n",
    "        df_cis_report.iat[j, 1] = df_cis_filtered.at[i, 'Stationing (ft)']\n",
    "        df_cis_report.iat[j, 2] = df_cis_filtered.at[i, 'Latitude']\n",
    "        df_cis_report.iat[j, 3] = df_cis_filtered.at[i, 'Longitude']\n",
    "\n",
    "        # End\n",
    "        df_cis_report.iat[j, 4] = df_cis_filtered.at[i + 1, 'Station']\n",
    "        df_cis_report.iat[j, 5] = df_cis_filtered.at[i + 1, 'Stationing (ft)']\n",
    "        df_cis_report.iat[j, 6] = df_cis_filtered.at[i + 1, 'Latitude']\n",
    "        df_cis_report.iat[j, 7] = df_cis_filtered.at[i + 1, 'Longitude']\n",
    "\n",
    "        # Length\n",
    "        df_cis_report.iat[j, 8] = df_cis_report.iat[j, 4] - df_cis_report.iat[j, 0]\n",
    "\n",
    "        # Counters\n",
    "        j += 1\n",
    "        i += 2\n",
    "\n",
    "    # Deletes station columns\n",
    "    df_cis_report = df_cis_report.drop(df_cis_report.iloc[:, [0, 4]], axis=1)\n",
    "\n",
    "    # Save to file\n",
    "    excel_name = f\"CIS Exception Report ({filtered_data_list[0].split('.csv')[0]}).xlsx\"\n",
    "    writing_mode = 'w'\n",
    "\n",
    "    if os.path.exists(os.path.join(output_path, excel_name)):\n",
    "        writing_mode = 'a'\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(output_path, excel_name),\n",
    "                        mode=writing_mode, engine='openpyxl') as writer:\n",
    "        df_cis_report.to_excel(writer, startrow=4,\n",
    "                               sheet_name='More Negative than -1.2V (Off)',\n",
    "                               index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:43.617081Z",
     "start_time": "2024-04-09T16:27:43.482228Z"
    }
   },
   "id": "cef9c6f64e96e6d8",
   "outputs": [],
   "execution_count": 638
  },
  {
   "cell_type": "code",
   "source": [
    "if df_cis_filtered.shape[0] != 0:\n",
    "    wb = load_workbook(os.path.join(output_path, excel_name))\n",
    "    sheet = wb['More Negative than -1.2V (Off)']\n",
    "\n",
    "    # Company name with pipeline ID\n",
    "    sheet.cell(1, 1).value = f\"{client} ({filtered_data_list[0].split('SN')[0][:-1]})\"\n",
    "\n",
    "    # Station numbers surveyed\n",
    "    sheet.cell(2, 1).value = (\n",
    "        f\"{filtered_data_list[0].split('SN')[1].split()[0]} to \"\n",
    "        f\"{filtered_data_list[0].split('SN')[2].split('.')[0]}\"\n",
    "    )\n",
    "\n",
    "    # Start\n",
    "    sheet.cell(4, 1).value = 'Start'\n",
    "\n",
    "    # End\n",
    "    sheet.cell(4, 4).value = 'End'\n",
    "\n",
    "    # Total pipeline distance with issues\n",
    "    total_feet = round(sum(total_miles_list * 5280))\n",
    "    total_miles = round(sum(total_miles_list), 2)\n",
    "    sheet.cell(last_index + 7, 1).value = (\n",
    "        f\"Total pipeline distance surveyed = {total_feet} feet or {total_miles} miles\"\n",
    "    )\n",
    "    total_length = df_cis_report['Length (ft)'].sum()\n",
    "    length_percent = round(total_length / sum(total_miles_list * 5280) * 100, 2)\n",
    "    sheet.cell(last_index + 8, 1).value = (\n",
    "        f\"Total pipeline distance more negative than -1.2V 'Off' = \"\n",
    "        f\"{total_length} feet ({length_percent} %)\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:43.674034Z",
     "start_time": "2024-04-09T16:27:43.618039Z"
    }
   },
   "id": "4212f3b28057fe92",
   "outputs": [],
   "execution_count": 639
  },
  {
   "cell_type": "code",
   "source": [
    "if df_cis_filtered.shape[0] != 0:\n",
    "    # Font\n",
    "    sheet.cell(1, 1).font = Font(size=14, bold=True)\n",
    "    sheet.cell(2, 1).font = Font(italic=True)\n",
    "    sheet.cell(4, 1).font = Font(bold=True)\n",
    "    sheet.cell(4, 4).font = Font(bold=True)\n",
    "    sheet.cell(4, 7).font = Font(bold=True)\n",
    "    sheet.cell(4, 8).font = Font(bold=True)\n",
    "    sheet.cell(last_index + 7, 1).font = Font(bold=True)\n",
    "    sheet.cell(last_index + 8, 1).font = Font(bold=True)\n",
    "\n",
    "    # Merging\n",
    "    sheet.merge_cells('A1:H1')\n",
    "    sheet.merge_cells('A2:H2')\n",
    "    sheet.merge_cells('A4:C4')\n",
    "    sheet.merge_cells('D4:F4')\n",
    "    sheet.cell(4, 7).value = sheet.cell(5, 7).value\n",
    "    sheet.merge_cells('G4:G5')\n",
    "    sheet.cell(4, 8).value = sheet.cell(5, 8).value\n",
    "    sheet.merge_cells('H4:H5')\n",
    "\n",
    "    # Alignment\n",
    "    i = 0\n",
    "\n",
    "    while i < (last_index + 5):\n",
    "        for c in sheet['A1:H' + str(last_index + 5)][i]:\n",
    "            c.alignment = Alignment(horizontal='center', vertical='center')\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    # Borders\n",
    "    i = 0\n",
    "    thin = Side(border_style='thin', color='000000')\n",
    "    white_border = Side(border_style='thin', color='FFFFFF')\n",
    "\n",
    "    while i < (last_index + 5):\n",
    "        # 3rd row\n",
    "        if i == 2:\n",
    "            for c in sheet['A1:H' + str(last_index + 5)][i]:\n",
    "                c.border = Border(left=white_border, right=white_border)\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        for c in sheet['A1:H' + str(last_index + 5)][i]:\n",
    "            c.border = Border(top=thin, left=thin, right=thin, bottom=thin)\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    # Column widths\n",
    "    for col in 'ABCDEFG':\n",
    "        sheet.column_dimensions[col].width = 15\n",
    "\n",
    "    sheet.column_dimensions['H'].width = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:44.261749Z",
     "start_time": "2024-04-09T16:27:43.675684Z"
    }
   },
   "id": "724e5853ee71508a",
   "outputs": [],
   "execution_count": 640
  },
  {
   "cell_type": "code",
   "source": [
    "# Save to excel\n",
    "if df_cis_filtered.shape[0] != 0:\n",
    "    wb.save(os.path.join(output_path, excel_name))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:44.303428Z",
     "start_time": "2024-04-09T16:27:44.262629Z"
    }
   },
   "id": "e4abc32eac968e75",
   "outputs": [],
   "execution_count": 641
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Log File",
   "id": "bc95f5599cb93eb3"
  },
  {
   "cell_type": "code",
   "source": [
    "# Current date and time\n",
    "e = datetime.datetime.now()\n",
    "execution_time = time.time() - start_time\n",
    "minutes, seconds = divmod(execution_time, 60)\n",
    "\n",
    "# Modify log file with information of interest\n",
    "with open(log_path, 'a') as f:\n",
    "    f.write(f\"\\nDuplicated GPS Pairs: {df_duplicates['Station'].value_counts().sum()}\\n\")\n",
    "    f.write(f\"Standard Deviation (GPS): {round(std, 3)}\\n\")\n",
    "    f.write(f\"On Measurements: {on_measurements}\\n\")\n",
    "    f.write(f\"Off Measurements: {off_measurements}\\n\")\n",
    "    f.write(f\"Ratio (On/Off): {on_measurements / off_measurements}\\n\\n\")\n",
    "    f.write(f\"User: {socket.gethostname()}\\n\")\n",
    "    f.write(f'{e.strftime(\"%b, %d, %Y\")}, {e.hour:02d}:{e.minute:02d}:{e.second:02d}')\n",
    "    f.write('\\n')\n",
    "    f.write(f\"Execution Time ({int(minutes)}:{int(seconds)})\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:27:44.314286Z",
     "start_time": "2024-04-09T16:27:44.304274Z"
    }
   },
   "id": "97a06a50780ee69b",
   "outputs": [],
   "execution_count": 642
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
